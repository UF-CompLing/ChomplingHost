{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Title: Sentiment Analysis Example 1\n",
      "# Author: Dax Gerts\n",
      "# Date: 2 February 2016\n",
      "# Description: introductory example to sentiment analysis with python-nltk, based heavily on example provided by at www.nltk.org/howto/sentiment.html\n",
      "#   Example uses the 'sentiment anlyzer' tool to prepare data for classification with Naive Bayes Classifier\n",
      "\n",
      "## Modules\n",
      "\n",
      "# 1. NaiveBayesClassifier (machine learning method)\n",
      "\n",
      "# Naive Bayes Classifier is the machine learning model used in this example\n",
      "# More info https://en.wikipedia.org/wiki/Naive_Bayes_classifier\n",
      "\n",
      "from nltk.classify import NaiveBayesClassifier\n",
      "\n",
      "# 2. Subjectivity (the data)\n",
      "\n",
      "# Corpus of phrases divided between subjective/objective\n",
      "\n",
      "# \"The Subjectivity Dataset contains 5000 subjective and 5000 objective processed sentences.\"\n",
      "# More info www.nltk.org/howto/corpus.html\n",
      "\n",
      "# For use in github notebook must manually download corpora\n",
      "nltk_dir = \"~nltk_data\"\n",
      "if nltk_dir not in nltk.data.path:\n",
      "        nltk.data.path.insert(0,nltk_dir)\n",
      "nltk.download(\"subjectivity\",download_dir=nltk_dir)\n",
      "#\n",
      "\n",
      "from nltk.corpus import subjectivity\n",
      "\n",
      "# 3. NLTK Sentiment Tools\n",
      "\n",
      "# The NLTK's collection of sentiment analysis tools\n",
      "# More info www.nltk.org\n",
      "\n",
      "from nltk.sentiment import SentimentAnalyzer\n",
      "from nltk.sentiment.util import *\n",
      "\n",
      "## Build training and testing data sets\n",
      "\n",
      "# Size of dataset(s)\n",
      "\n",
      "n = 1000\n",
      "\n",
      "# Get \"n\" subjective and objective phrases from subjectivity corpus\n",
      "\n",
      "subjective = [(sentences,'subj') for sentences in subjectivity.sents(categories='subj')[:n]]\n",
      "objective = [(sentences,'obj') for sentences in subjectivity.sents(categories='obj')[:n]]\n",
      "\n",
      "# Here's what the first item in \"subjective\" looks like\n",
      "# Note that it's stores as (phrase, label)\n",
      "\n",
      "subjective[0]\n",
      "\n",
      "# Create separate training and test data sets, this is pretty standard in any data mining/machine learning task\n",
      "# The typical split is, as seen here (training = 80%, train = 20%)\n",
      "\n",
      "training_subjective = subjective[:int(.8*n)]\n",
      "test_subjective = subjective[int(.8*n):n]\n",
      "training_objective = objective[:int(.8*n)]\n",
      "test_objective = objective[int(.8*n):n]\n",
      "\n",
      "# Now aggregate the training and test sets\n",
      "\n",
      "training = training_subjective + training_objective\n",
      "test = test_subjective + test_objective\n",
      "\n",
      "## Apply sentiment analysis to data to extract new \"features\"\n",
      "\n",
      "# Initialize sentiment analyzer object\n",
      "\n",
      "sentiment_analyzer = SentimentAnalyzer()\n",
      "\n",
      "# Mark all negative words in training data, using existing list of negative words\n",
      "\n",
      "all_negative_words = sentiment_analyzer.all_words([mark_negation(data) for data in training])\n",
      "\n",
      "unigram_features = sentiment_analyzer.unigram_word_feats(all_negative_words, min_freq=4)\n",
      "len(unigram_features)\n",
      "sentiment_analyzer.add_feat_extractor(extract_unigram_feats,unigrams=unigram_features)\n",
      "\n",
      "training_final = sentiment_analyzer.apply_features(training)\n",
      "test_final = sentiment_analyzer.apply_features(test)\n",
      "\n",
      "## Traing model and test\n",
      "\n",
      "model = NaiveBayesClassifier.train\n",
      "classifer = sentiment_analyzer.train(model, training_final)\n",
      "\n",
      "for key, value in sorted(sentiment_analyzer.evaluate(test_final).items()):\n",
      "    print('{0}: {1}'.format(key,value))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package subjectivity to ~nltk_data...\n",
        "[nltk_data]   Unzipping corpora/subjectivity.zip."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training classifier"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Evaluating NaiveBayesClassifier results..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy: 0.835"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F-measure [obj]: 0.826315789474\n",
        "F-measure [subj]: 0.842857142857\n",
        "Precision [obj]: 0.872222222222\n",
        "Precision [subj]: 0.804545454545\n",
        "Recall [obj]: 0.785\n",
        "Recall [subj]: 0.885\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
